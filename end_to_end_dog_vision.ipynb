{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "end-to-end-dog-vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bTOTqjJACSh_poxEeaymzsKQb76flGi1",
      "authorship_tag": "ABX9TyNRZcUPI+4CuFlYGXuMguiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachi-khandelwal/Dog-Vision-MultiClassification-Project/blob/master/end_to_end_dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToMI1HKTNZCQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd84bWcuNlD-",
        "colab_type": "text"
      },
      "source": [
        "# üê∂End-To-End MultiClass Dog Breed Identification\n",
        "\n",
        "this Notebook builds an end-to-end multi-class image classifier using TensolrFlow 2.0 and Tensorflow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifying the breed of the dog given in the image of a dog.\n",
        "\n",
        "When I am roaming around in my locality a dog passed and I wanted to Know the breed of the dog.üòäüòÅ\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "The Data we're using is from Kaggle's Dog Breed identification competition.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "The evaluation is the file with Prediction Probabilitiesfor each dog breed in the image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "## 4. Features\n",
        "\n",
        "Some Information about the Data:\n",
        "* We're dealing with images (unstructured Data) so its probably best to use Deep learning /Transfer Learning.\n",
        "* There are 120 breeds of dogs (this means there are 120 different classes).\n",
        "* There are around 10K images in Trainng set (These Images have Labels).\n",
        "* There are around 10k images in Test set (These Images don't have labels).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMeuwQS1Tgw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the data into Google Drive.\n",
        "# !unzip \"/content/drive/My Drive/Dog vision/dog-breed-identification.zip\" -d \"drive/My Drive/Dog vision\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5zGmNf9TAn8",
        "colab_type": "text"
      },
      "source": [
        "# Get our Workspace Ready!\n",
        "* Import Tensorflow 2.x ‚úÖ\n",
        "* Import TensorFlow Hub‚úÖ\n",
        "* Make sure we're using a GPU \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utbI6ribVD0c",
        "colab_type": "text"
      },
      "source": [
        "Import necessary Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwwyr7N9TAO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import TensorFlow into COlAB\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version:\",tf.__version__)\n",
        "# Import Tensorflow HUB\n",
        "import tensorflow_hub as hub\n",
        "print(\"Tensorflow hub version:\",hub.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ_mNnvnfzhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check If a GPU available\n",
        "print(\"GPU\", \"available YEP!\" if tf.config.list_physical_devices(\"GPU\") else \"not available :( \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTmOSfURdPX6",
        "colab_type": "text"
      },
      "source": [
        "## Getting our Data ready! (turning into tensors)\n",
        "With all ML models our data must be in numerical format. So that's what we're going to do.\n",
        "Turning our images into tensors(Numerical Representation)\n",
        "\n",
        "Let's start by accessing our data and checking labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHGobkr1ebAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkout the data labels\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "labels_csv = pd.read_csv(\"drive/My Drive/Dog vision/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "labels_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WOrULQEhPhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_csv.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh04TpQCfd_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see the no. of images of each breed\n",
        "labels_csv[\"breed\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0JZQqptiDs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's visualize it\n",
        "ax = labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25fqT1qXiQnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To display the Images\n",
        "from IPython.display import display, Image\n",
        "# Image(\"drive/My Drive/Dog vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zweVQgfW8bm8",
        "colab_type": "text"
      },
      "source": [
        "## Getting Images and their labels\n",
        "Let's get list of our images file Pathnames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss2o2-g_-TGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create filenames from ID\n",
        "filenames = [\"drive/My Drive/Dog vision/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
        "filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy3DZ5Z9-oVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking whether the number of filenames mathcing to the actual images files in train folder\n",
        "import os\n",
        "if len(os.listdir(\"drive/My Drive/Dog vision/train/\")) == len(filenames):\n",
        "  print(\"Number of files Matched Proceed!\")\n",
        "else:\n",
        "  print(\"Files Not Matched Erorr!\")\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjzwrVFCkVBk",
        "colab_type": "text"
      },
      "source": [
        "### Since Now we've got our FilePath ready, let's prepare our labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPeRWlw559Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = labels_csv['breed'].to_numpy()  #to_numpy() converts into numpy array\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ViQniVlDRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSoICuThlLbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let's see if number of labels matches number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"No. of Labels Matches No. of Filenames! Proceed.\")\n",
        "else:\n",
        "  print(\"Check Again! Labels does't matches Filenames\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHk0toHmJjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "unique_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd4sOjFmnrLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn single label into an array\n",
        "print(labels[1])\n",
        "labels[1] == unique_breeds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhqINtLfqq4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn every label into a Boolean Array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2cncUBrq2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(boolean_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDHxtLGjs9_X",
        "colab_type": "text"
      },
      "source": [
        "## Turning **Boolean Labels into Integers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq57D21ktIWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(labels[1]) #Original Label\n",
        "print(np.where(unique_breeds == labels[1])) #index where label occur in unique_breeds \n",
        "print(boolean_labels[1].argmax()) #argmax returns max value in the array\n",
        "print(boolean_labels[1].astype(int)) #converts boolean values into Int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRM9JQEwxiPf",
        "colab_type": "text"
      },
      "source": [
        "## Creating our own Validation set\n",
        "Since kaggle doesn't provide any validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgLZRavtYB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup X and Y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoAlt3SUysqt",
        "colab_type": "text"
      },
      "source": [
        "Since Experimenting with 10k images might take long, so we'll experiment with ~1000 images at first & increases as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxrTri_GygNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set number of images\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DQFWw1w1QSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's split our data into train & valid sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# let's split our data into train and valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X[:NUM_IMAGES],\n",
        "                                                      y[:NUM_IMAGES],\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=42)\n",
        "len(X_train), len(X_valid), len(y_train), len(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swCXX93p36wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's peek into our train and test data\n",
        "X_train[:5], y_train[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezBGLfNAQy6_",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing of Image (Turning into Tensors)\n",
        "To process our images into Tensors we're going to write a function which does few things.\n",
        "1. Take Image filepath as input.\n",
        "2. Use Tensorflow to read the image file and save it to a variable, `image`.\n",
        "3. Turn our `image` (jpg) into Tensors.\n",
        "4. Normalise our image (convert our color channel values from 0-255 to 0-1). \n",
        "5. Resize the image to be a shape of (224,224).\n",
        "6. Return the modified image.\n",
        "\n",
        "Before creating function let's peek how a tensor image look like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNvX-2a4Hwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert single image into numpy array\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42])\n",
        "len(image),image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tspa27uLX0MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert single image into tensor\n",
        "tf.constant(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9YcrN6YNNLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Create a Function for preprocessing\n",
        "def preprocess(image_path, img_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Preprocess The Image and convert into tensors.\n",
        "  \"\"\"\n",
        "  # Input the Image file path\n",
        "  image = tf.io.read_file(image_path)\n",
        "\n",
        "  # Turn the jpeg image into numerical Tensors with 3 color channel(Red, Green and Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "  # normalise the color channel values from 0-255 to 0-1\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "  # Resize the image\n",
        "  image = tf.image.resize(image,[img_size, img_size])\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcxjywzLYeNP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aQld0JxYfwU",
        "colab_type": "text"
      },
      "source": [
        "## Turning our Data into Batches\n",
        "Why turn our data into batches?\n",
        "let's say if your are trying to process 10000 images at one go...\n",
        "\n",
        "They all might not fit into memory.\n",
        "\n",
        "So that's why we do 32(batch size) images at a time.\n",
        "\n",
        "In order to use Tensorflow effectively, we need our data in the form of tensor tuples: `(image, label)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWAWQNmbft5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a simple function to return a tuple\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  returns the image and label into tuple form\n",
        "  \"\"\"\n",
        "  image = preprocess(image_path)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWh66ndJjdOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(preprocess(X[42]),tf.constant(y[42]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FTOcCsHKRO",
        "colab_type": "text"
      },
      "source": [
        "Now've got a way to turn our data into Tuples of Tensors in the form of `(image, label)`, Let's make a function to create Batches for our data `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFxGCwlhj5b-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the batch size, 32 is good start\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a Function to Turn Data into Batches\n",
        "def create_data_batches(X, y, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates Batches of data out of image (X) and label (y) pairs.\n",
        "  Shuffle the data if it's training data but doesn't shuffle valid data.\n",
        "  Also accepts test data as input(no labels).\n",
        "  \"\"\"\n",
        "  # If the Data is Test data, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating Test Data Batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) #Only filepaths(no label)\n",
        "\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "\n",
        "    return data_batch\n",
        "\n",
        "  # If the Data is Valid data, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating Valid data batches\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), #Filepath\n",
        "                                               tf.constant(y))) #Label\n",
        "\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # If the Data is Training data, we had to shuffle it before processing Images\n",
        "  # As it will save Computation Time\n",
        "  else:\n",
        "    print(\"Creating Training Data Batches...\")\n",
        "    # Turn Filepaths and Labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), \n",
        "                                               tf.constant(y)))\n",
        "    # Shuffling the pathnames and labels before Mapping image process function\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "\n",
        "    # Create (image, label) tuples, it also turns the image path into processed image\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "  return data_batch\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibdfRoNfUIIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating Validation and training data BATCHES\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "valid_data = create_data_batches(X_valid, y_valid, valid_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gA1WlflUdr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check out the attributes of our data Batches\n",
        "train_data.element_spec, valid_data.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5El7ss7Qvzw1",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Data Batches\n",
        "Our Data is in batches, this can be a liitle hard to comprehend let's visulaise our data specifically 25 Images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkECzheuwOld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function to visulaise batches of Images\n",
        "def image_batch_visualise(image, label):\n",
        "  \"\"\"\n",
        "  Displays a batch of 25 image batch with their labels.\n",
        "  \"\"\"\n",
        "  # Set the figsize\n",
        "  plt.figure(figsize=(10,10))\n",
        "  #Set the loops to display 25 images\n",
        "  for i in range(25):\n",
        "     # set the axis subplots\n",
        "     ax = plt.subplot(5, 5, i+1)\n",
        "     # Display image\n",
        "     plt.imshow(image[i])\n",
        "     # Set the title over the image using label\n",
        "     plt.title(unique_breeds[label[i].argmax()],{'color':'white','fontweight':'23'})\n",
        "     # set the grid off\n",
        "     plt.axis(\"off\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0oTgR6zvlz",
        "colab_type": "text"
      },
      "source": [
        "Now we've craeted our function to visulise the images but before that we first need to `UNBATCH` the proceesed images to visualise them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9A0ITpNzvRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels = next(train_data.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A--Z1xC1HL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_images), len(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nSYrzVx1VhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's visualise Training batch\n",
        "image_batch_visualise(train_images, train_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ezWUZIk3155",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's visualise valid batch\n",
        "valid_images, valid_labels = next(valid_data.as_numpy_iterator())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ASemmW4Qli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch_visualise(valid_images, valid_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyR1Lp4H8Xpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mkzp4Ix-cBT",
        "colab_type": "text"
      },
      "source": [
        "# Building a Model\n",
        "Before building a model we need to specify certain things to define.\n",
        "1. The input shape (our image shape in the form of tensors) to our model.\n",
        "2. the output shape (our image labels in the form of tensors) to our model.\n",
        "3. URL of the Model which we're going to use from  Tensorflow Hub.\n",
        "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNfhPSDj--3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup Input shape (Images)\n",
        "INPUT_SHAPE = [None, IMG_SIZE,IMG_SIZE, 3] #batch, width, height, color channel\n",
        "\n",
        "# Setup OutPut shape (labels)\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# URL of TensorFlow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTe0su3I6w2c",
        "colab_type": "text"
      },
      "source": [
        "Now we've input, output and our model ready to go, Let's put them together using Keras deep learning model!\n",
        "\n",
        "Knowing this Let's create a model which does following tasks:\n",
        "* Takes input, output and model we've chosen as parameters.\n",
        "* Define the layers in Keras model as Sequential manner(do this, then this, then that).\n",
        "* Complies the model(say evaluate and improved).\n",
        "* Build the model tell it the input shape it'll be getting.\n",
        "* Returns the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYQhRIx383Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model=MODEL_URL):\n",
        "  print(\" Building model with\", MODEL_URL)\n",
        "\n",
        "  #setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "          hub.KerasLayer(MODEL_URL), #Layer 1 (input Layer)\n",
        "          tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n",
        "                                activation='softmax') #Layer 2 output layer\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AnnQ92dAtiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "624ac4c0-f604-44f1-90b9-6ac0b9f05d5e"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Building model with https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_1 (KerasLayer)   multiple                  5432713   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  120240    \n",
            "=================================================================\n",
            "Total params: 5,552,953\n",
            "Trainable params: 120,240\n",
            "Non-trainable params: 5,432,713\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLKPgqNnP0ty",
        "colab_type": "text"
      },
      "source": [
        "###  Creating Callbacks\n",
        "Callback are helper functions used in model training to do alot of things like save the Progress of the model, check it's progress and stop training model if it's stop improving.\n",
        "\n",
        "We'll create two callbacks for TensorBoard one for saving it's progress and another for preventing model form traing too long.\n",
        "\n",
        "### TensorBoard Callback\n",
        "\n",
        "To set up TensorBoard callback, we need to do 3 things..\n",
        "* Load the TensorBoard extension.\n",
        "* Create a TensorBoard callback which is able to save logs to a directory and pass it to the `fit()` model's function.\n",
        "* Visualize our model training logs with the `%tensorboard` magic function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBw2Mw_SBUng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load tensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym-SGCxiWn-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "#Create function to build a tensorBoard callback\n",
        "def create_tensorboard_callback():\n",
        "  #Create log directory to store tensorboard logs\n",
        "  logdir = os.path.join(\"drive /My drive/Dog vision/logs\",\n",
        "                        #Make it so logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "                        \n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYVhCNo5ZzX0",
        "colab_type": "text"
      },
      "source": [
        "### Early stopping callback\n",
        "\n",
        "Early stopping callback stops our model from overfitting by stopping training if a certain evaluation metrics stops Improving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVLx6_iXWq5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkAXc255eLs6",
        "colab_type": "text"
      },
      "source": [
        "## Training a model (on subset data)\n",
        " Our first model is only going train 1,000 images, to make sure everything works fine..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIuq03bod4vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 100 #@param {type:'slider',min:10, max:100, step:10}\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWN38gythTOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fe8ef0bb-b3e4-43fe-97c5-2d4551296c83"
      },
      "source": [
        "# Check to make sure we'are still running ona  GPU\n",
        "print(\"GPU available Bravo!\" if tf.config.list_physical_devices('GPU') else \"Not available ‡≤†_‡≤†  \")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available Bravo!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R6DyDVBh0r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}